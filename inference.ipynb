{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f89c4d78-d2c7-45cf-a721-486bef8a2317",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load library\n",
    "import argparse\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "from mypath import Path\n",
    "from dataloaders import make_data_loader\n",
    "from modeling.sync_batchnorm.replicate import patch_replication_callback\n",
    "from modeling.deeplab import *\n",
    "from utils.loss import SegmentationLosses\n",
    "from utils.calculate_weights import calculate_weigths_labels\n",
    "from utils.lr_scheduler import LR_Scheduler\n",
    "from utils.saver import Saver\n",
    "from utils.summaries import TensorboardSummary\n",
    "from utils.metrics import Evaluator\n",
    "\n",
    "from dataloaders.datasets.lits import LiverSegmentation, TumorSegmentation\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import argparse\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import time\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a1a44cd7-0aab-4205-9491-f70c1a02fdff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage import morphology\n",
    "\n",
    "def surfd(input1, input2, sampling=1, connectivity=1):\n",
    "    \n",
    "    input_1 = np.atleast_1d(input1.astype(np.bool))\n",
    "    input_2 = np.atleast_1d(input2.astype(np.bool))\n",
    "    \n",
    "\n",
    "    conn = morphology.generate_binary_structure(input_1.ndim, connectivity)\n",
    "\n",
    "    S = input_1 ^ morphology.binary_erosion(input_1, conn)\n",
    "    Sprime = input_2 ^ morphology.binary_erosion(input_2, conn)\n",
    "\n",
    "    \n",
    "    dta = morphology.distance_transform_edt(~S,sampling)\n",
    "    dtb = morphology.distance_transform_edt(~Sprime,sampling)\n",
    "    \n",
    "    sds = np.concatenate([np.ravel(dta[Sprime!=0]), np.ravel(dtb[S!=0])])\n",
    "       \n",
    "    \n",
    "    return sds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9d7d7c0-4f89-44ff-b85b-28ed02663054",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('-f')\n",
    "parser.add_argument('--batch-size', type=int, default=5)\n",
    "parser.add_argument('--base-size', type=int, default=256)\n",
    "parser.add_argument('--crop-size', type=int, default=256)\n",
    "parser.add_argument('--mode', type=str, default='vis')\n",
    "parser.add_argument('--kind', type=str, default='liver')\n",
    "parser.add_argument('--model-path', type=str, default='models/95_liver33.pth.tar')\n",
    "args = parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a4d3622-9a58-49f5-8159-fa7d26266088",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"http://data.lip6.fr/cadene/pretrainedmodels/xception-b5690688.pth\" to /root/.cache/torch/hub/checkpoints/xception-b5690688.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccdd6c944b544cae9a1ca7dc7797b848",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/87.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_80/460050524.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# load model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDeepLab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackbone\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'xception'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_stride\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msync_bn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfreeze_bn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# ckpt = torch.load('run/lits_tumor/resume-tumor-bce-crop/experiment_0/_checkpoint37.pth.tar')#67 0.8809 0.8809\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mckpt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#72\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workspace/cutiekath/pytorch-deeplab-xception/modeling/deeplab.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, backbone, output_stride, num_classes, sync_bn, freeze_bn)\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0mBatchNorm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBatchNorm2d\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackbone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_backbone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbackbone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_stride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBatchNorm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maspp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_aspp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbackbone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_stride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBatchNorm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_decoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackbone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBatchNorm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workspace/cutiekath/pytorch-deeplab-xception/modeling/backbone/__init__.py\u001b[0m in \u001b[0;36mbuild_backbone\u001b[0;34m(backbone, output_stride, BatchNorm)\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResNet101\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_stride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBatchNorm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mbackbone\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'xception'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mxception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAlignedXception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_stride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBatchNorm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mbackbone\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'drn'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdrn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrn_d_54\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBatchNorm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workspace/cutiekath/pytorch-deeplab-xception/modeling/backbone/xception.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, output_stride, BatchNorm, pretrained)\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[0;31m# Load pretrained model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpretrained\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_pretrained_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workspace/cutiekath/pytorch-deeplab-xception/modeling/backbone/xception.py\u001b[0m in \u001b[0;36m_load_pretrained_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_load_pretrained_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 248\u001b[0;31m         \u001b[0mpretrain_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_zoo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'http://data.lip6.fr/cadene/pretrainedmodels/xception-b5690688.pth'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m         \u001b[0mmodel_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m         \u001b[0mstate_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/hub.py\u001b[0m in \u001b[0;36mload_state_dict_from_url\u001b[0;34m(url, model_dir, map_location, progress, check_hash, file_name)\u001b[0m\n\u001b[1;32m    551\u001b[0m             \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHASH_REGEX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# r is Optional[Match[str]]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhash_prefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 553\u001b[0;31m         \u001b[0mdownload_url_to_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcached_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhash_prefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprogress\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprogress\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_legacy_zip_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcached_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/hub.py\u001b[0m in \u001b[0;36mdownload_url_to_file\u001b[0;34m(url, dst, hash_prefix, progress)\u001b[0m\n\u001b[1;32m    439\u001b[0m                   unit='B', unit_scale=True, unit_divisor=1024) as pbar:\n\u001b[1;32m    440\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m                 \u001b[0mbuffer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8192\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    442\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/http/client.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    453\u001b[0m             \u001b[0;31m# Amount is given, implement using readinto\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m             \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytearray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 455\u001b[0;31m             \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadinto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    456\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mmemoryview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtobytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/http/client.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    497\u001b[0m         \u001b[0;31m# connection, and the user is reading more bytes than will be provided\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m         \u001b[0;31m# (for example, reading in 1k chunks)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 499\u001b[0;31m         \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadinto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    500\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m             \u001b[0;31m# Ideally, we would raise IncompleteRead if the content-length\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    667\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 669\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    670\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1239\u001b[0m                   \u001b[0;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1240\u001b[0m                   self.__class__)\n\u001b[0;32m-> 1241\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1242\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1243\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1097\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1098\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1099\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1100\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1101\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# load model\n",
    "model = DeepLab(num_classes=2, backbone='xception', output_stride=16, sync_bn=False, freeze_bn=False)\n",
    "\n",
    "# ckpt = torch.load('run/lits_tumor/resume-tumor-bce-crop/experiment_0/_checkpoint37.pth.tar')#67 0.8809 0.8809\n",
    "ckpt = torch.load(args.model_path)#72 \n",
    "state_dict = ckpt['state_dict']\n",
    "model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab7df8d-5f80-40b5-b8ef-44ea46bd0bfe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "if args.kind == 'liver':\n",
    "    dataset_test = LiverSegmentation(args, split=args.mode)\n",
    "if args.kind == 'tumor':\n",
    "    dataset_test = TumorSegmentation(args, split=args.mode)\n",
    "print(\"num test img: \", len(dataset_test))\n",
    "dataloader = DataLoader(dataset_test, batch_size=args.batch_size, shuffle=True, num_workers=0)\n",
    "\n",
    "# gpu use\n",
    "device = 'cuda'\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# initialize scores\n",
    "cnt = 0\n",
    "total_precision = 0\n",
    "total_recall = 0\n",
    "total_time = 0\n",
    "total_cos = 0\n",
    "total_voe = 0\n",
    "total_assd = 0\n",
    "total_vd = 0\n",
    "# Dice, jaccard, VOE, ASSD, RVD, MSSD \n",
    "# run inference\n",
    "for i, sample in enumerate(dataloader):\n",
    "    image, target = sample['image'], sample['label']\n",
    "    image = image.to(device)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    with torch.no_grad():\n",
    "        output = model(image)\n",
    "    timedelta = time.time() - start_time\n",
    "    total_time += timedelta\n",
    "    \n",
    "    pred = output.data.cpu().numpy()\n",
    "    target = target.cpu().numpy()\n",
    "    pred = np.argmax(pred, axis=1)\n",
    "    # print(np.unique(pred))\n",
    "    # print(np.unique(target))\n",
    "    \n",
    "    image = image.cpu().numpy()\n",
    "    for idx in range(len(pred)):\n",
    "        if args.mode == 'val':\n",
    "            ## scoring\n",
    "            pred_ = pred[idx].astype(np.uint8)\n",
    "            target_ = target[idx].astype(np.uint8)\n",
    "\n",
    "            intersection = np.logical_and(target_, pred_)\n",
    "            union = np.logical_or(target_, pred_)\n",
    "            voe = 1.0 - np.sum(intersection)/np.sum(union)\n",
    "            sds = surfd(target_, pred_)\n",
    "            if len(sds) == 0:\n",
    "                assd = 0\n",
    "            else:\n",
    "                assd = sds.mean()\n",
    "            if np.sum(target_) == 0:\n",
    "                vd = 1.0\n",
    "            else:\n",
    "                vd = abs((int(np.sum(pred_)) - int(np.sum(target_))) / float(np.sum(target_)))\n",
    "            # iou_score = np.sum(intersection) / np.sum(union)\n",
    "            tp = np.sum(np.logical_and(target_ == 1, pred_ == 1))/256**2\n",
    "            fp = np.sum(np.logical_and(target_ == 0, pred_ == 1))/256**2\n",
    "            tn = np.sum(np.logical_and(target_ == 0, pred_ == 0))/256**2\n",
    "            fn = np.sum(np.logical_and(target_ == 1, pred_ == 0))/256**2\n",
    "\n",
    "            target_ = target_.ravel()\n",
    "            pred_ = pred_.ravel()\n",
    "\n",
    "            cos_sim = np.dot(target_, pred_)/(np.linalg.norm(target_)*np.linalg.norm(pred_))\n",
    "            precision = tp/(tp+fp)\n",
    "            recall = tp/(tp+fn)\n",
    "            voe = np.nan_to_num(voe, nan=1.0)\n",
    "            cos_sim = np.nan_to_num(cos_sim, nan=1.0)\n",
    "            precision = np.nan_to_num(precision, nan=1.0)\n",
    "            recall = np.nan_to_num(recall, nan=1.0)\n",
    "            \n",
    "            total_cos += cos_sim\n",
    "            total_precision+=precision\n",
    "            total_recall+=recall\n",
    "            total_voe += voe\n",
    "            total_assd+=assd\n",
    "            total_vd+=vd\n",
    "        elif args.mode == 'vis':\n",
    "            ##visualize(save)\n",
    "            pred_ = pred[idx].astype(np.uint8)\n",
    "            target_ = target[idx].astype(np.uint8)\n",
    "            pred_[pred_ != 0] = 255\n",
    "            target_[target_ != 0] = 255\n",
    "\n",
    "            img_tmp = np.transpose(image[idx], axes=[1, 2, 0])\n",
    "            img_tmp *= (0.229, 0.224, 0.225)\n",
    "            img_tmp += (0.485, 0.456, 0.406)\n",
    "            img_tmp *= 255.0\n",
    "            img_tmp = img_tmp.astype(np.uint8)\n",
    "\n",
    "            fig = plt.figure()\n",
    "            fig.tight_layout()\n",
    "\n",
    "            ax1 = fig.add_subplot(1, 3, 1)\n",
    "            ax1.imshow(target_, cmap='gray')\n",
    "            # ax1.set_title('Label')\n",
    "            ax1.axes.xaxis.set_visible(False)\n",
    "            ax1.axes.yaxis.set_visible(False)\n",
    "            ax2 = fig.add_subplot(1, 3, 2)\n",
    "            ax2.imshow(img_tmp, cmap=plt.cm.bone)\n",
    "            # ax2.set_title('Original')\n",
    "            ax2.axes.xaxis.set_visible(False)\n",
    "            ax2.axes.yaxis.set_visible(False)\n",
    "            ax3 = fig.add_subplot(1, 3, 3)\n",
    "            ax3.imshow(pred_, cmap='gray')\n",
    "            # ax3.set_title('Predict')\n",
    "            ax3.axes.xaxis.set_visible(False)\n",
    "            ax3.axes.yaxis.set_visible(False)\n",
    "\n",
    "            # plt.show()\n",
    "            os.makedirs('val/'+args.kind, exist_ok=True)\n",
    "            plt.savefig('val/'+args.kind+'/'+str(cnt)+'.png')\n",
    "        cnt+=1\n",
    "        print(cnt, end='\\r')\n",
    "\n",
    "if args.mode == 'val':\n",
    "    # print scores\n",
    "    avg_time = total_time/cnt\n",
    "    p = total_precision/cnt*100\n",
    "    r = total_recall/cnt*100\n",
    "    cos = total_cos/cnt*100\n",
    "    f1 = 2*p*r/(p+r)*100\n",
    "    voe = total_voe/cnt*100\n",
    "    assd = total_assd/cnt\n",
    "    vd = total_vd/cnt*100\n",
    "    print(f\"avg_time:{avg_time} precision:{p} recall:{r} dice:{f1} jaccard:{cos} voe:{voe} assd:{assd} vd:{vd}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "51689f5c-dd45-44fd-be69-25cd15c257b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook inference.ipynb to script\n",
      "[NbConvertApp] Writing 6906 bytes to inference.py\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbconvert --to script inference.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d0c60fc-d539-4cde-a124-c5fa188fa5ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
